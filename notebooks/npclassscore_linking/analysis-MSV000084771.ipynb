{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "defensive-thread",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this notebook, the paired data from MSV000084771 is analysed for the NPClassScore paper.\n",
    "\n",
    "The newly developed implementation of NPClassScore is used in combination with Metcalf scoring to discover BGC-MS/MS spectrum links in the MSV000084771 dataset. Validated links from the PoDP are used to validate the results.\n",
    "\n",
    "Sections:\n",
    "- Loading the MSV000084771 dataset\n",
    "- Scoring using the new NPClassScore method\n",
    "- Investigating NPClassScore cutoff\n",
    "- Counting number of links\n",
    "- Making plots showing the filtered links\n",
    "- Investigate known links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-photograph",
   "metadata": {},
   "source": [
    "## Loading MSV000084771 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "productive-constitution",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, csv, os\n",
    "# if running from clone of the git repo\n",
    "sys.path.append('../../prototype')\n",
    "\n",
    "# import the main NPLinker class. normally this all that's required to work\n",
    "# with NPLinker in a notebook environment\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nplinker.nplinker import NPLinker\n",
    "from nplinker.nplinker import Spectrum\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "friendly-point",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:02:03 [INFO] config.py:121, Loading from local data in directory /mnt/scratch/louwe015/NPLinker/own/nplinker_shared/nplinker_data/pairedomics/extracted/MSV000084771/\n",
      "18:02:03 [WARNING] loader.py:50, WARNING: unable to find extra_nodes_file in path \"/mnt/scratch/louwe015/NPLinker/own/nplinker_shared/nplinker_data/pairedomics/extracted/MSV000084771/quantification_table_reformatted/*.csv\"\n",
      "18:02:03 [WARNING] loader.py:50, WARNING: unable to find metadata_table_file in path \"/mnt/scratch/louwe015/NPLinker/own/nplinker_shared/nplinker_data/pairedomics/extracted/MSV000084771/metadata_table/metadata_table*.txt\"\n",
      "18:02:03 [WARNING] loader.py:50, WARNING: unable to find quantification_table_file in path \"/mnt/scratch/louwe015/NPLinker/own/nplinker_shared/nplinker_data/pairedomics/extracted/MSV000084771/quantification_table/quantification_table*.csv\"\n",
      "18:02:03 [INFO] loader.py:84, Trying to discover correct bigscape directory under /mnt/scratch/louwe015/NPLinker/own/nplinker_shared/nplinker_data/pairedomics/extracted/MSV000084771/bigscape\n",
      "18:02:03 [INFO] loader.py:87, Found network files directory: /mnt/scratch/louwe015/NPLinker/own/nplinker_shared/nplinker_data/pairedomics/extracted/MSV000084771/bigscape/network_files/2022-05-12_12-56-13_hybrids_glocal\n",
      "18:02:03 [INFO] loader.py:226, Updating bigscape_dir to discovered location /mnt/scratch/louwe015/NPLinker/own/nplinker_shared/nplinker_data/pairedomics/extracted/MSV000084771/bigscape/network_files/2022-05-12_12-56-13_hybrids_glocal\n",
      "18:02:03 [INFO] loader.py:648, Loaded global strain IDs (0 total)\n",
      "18:02:03 [INFO] loader.py:659, Loaded dataset strain IDs (11 total)\n",
      "18:02:04 [INFO] metabolomics.py:699, 11464 molecules parsed from MGF file\n",
      "18:02:05 [INFO] metabolomics.py:716, Found older-style GNPS dataset, no quantification table\n",
      "18:02:05 [WARNING] metabolomics.py:516, Unknown strain: Ctrl-FeMeOHGa.mzXML for cluster index 8\n",
      "18:02:05 [WARNING] metabolomics.py:516, Unknown strain: TerpA.mzXML for cluster index 187\n",
      "18:02:05 [WARNING] metabolomics.py:516, Unknown strain: TerpB.mzXML for cluster index 200\n",
      "18:02:05 [WARNING] metabolomics.py:516, Unknown strain: TerpC.mzXML for cluster index 204\n",
      "18:02:05 [WARNING] metabolomics.py:516, Unknown strain: 108RE.mzXML for cluster index 1137\n",
      "18:02:05 [WARNING] metabolomics.py:516, Unknown strain: 29-FeGa.mzXML for cluster index 1875\n",
      "18:02:05 [WARNING] metabolomics.py:516, Unknown strain: Ctrl-FeGa(old).mzXML for cluster index 2143\n",
      "18:02:05 [WARNING] metabolomics.py:531, 7 unknown strains were detected a total of 8540 times\n",
      "18:02:05 [WARNING] loader.py:577, Writing unknown strains from METABOLOMICS data to /mnt/scratch/louwe015/NPLinker/own/nplinker_shared/nplinker_data/pairedomics/extracted/MSV000084771/unknown_strains_met.csv\n",
      "18:02:05 [INFO] loader.py:584, Loading provided annotation files (/mnt/scratch/louwe015/NPLinker/own/nplinker_shared/nplinker_data/pairedomics/extracted/MSV000084771/result_specnets_DB)\n",
      "18:02:08 [INFO] genomics.py:485, Found 1816 MiBIG json files\n",
      "18:02:20 [WARNING] loader.py:516, 1 missing annotation tsv files:\n",
      "18:02:20 [WARNING] loader.py:518,   1/1: /mnt/scratch/louwe015/NPLinker/own/nplinker_shared/nplinker_data/pairedomics/extracted/MSV000084771/bigscape/network_files/2022-05-12_12-56-13_hybrids_glocal/Saccharides/Network_Annotations_Saccharides.tsv\n",
      "18:02:20 [WARNING] loader.py:516, 1 missing clustering tsv files:\n",
      "18:02:20 [WARNING] loader.py:518,   1/1: /mnt/scratch/louwe015/NPLinker/own/nplinker_shared/nplinker_data/pairedomics/extracted/MSV000084771/bigscape/network_files/2022-05-12_12-56-13_hybrids_glocal/Saccharides/Saccharides_clustering_c0.30.tsv\n",
      "18:02:20 [WARNING] loader.py:516, 1 missing network files:\n",
      "18:02:20 [WARNING] loader.py:518,   1/1: /mnt/scratch/louwe015/NPLinker/own/nplinker_shared/nplinker_data/pairedomics/extracted/MSV000084771/bigscape/network_files/2022-05-12_12-56-13_hybrids_glocal/Saccharides/Saccharides_c0.30.network\n",
      "18:02:20 [WARNING] loader.py:532, Product type Saccharides will be skipped due to missing files!\n",
      "18:02:20 [INFO] genomics.py:255, Using antiSMASH filename delimiters ['.', '_', '-']\n",
      "18:02:31 [INFO] genomics.py:392, # MiBIG BGCs = 0, non-MiBIG BGCS = 2183, total bgcs = 2183, GCFs = 300, strains=1827\n",
      "18:02:31 [INFO] genomics.py:449, Filtering MiBIG BGCs: removing 0 GCFs and 0 BGCs\n",
      "18:02:31 [INFO] genomics.py:399, # after filtering, total bgcs = 367, GCFs = 300, strains=11, unknown_strains=0\n",
      "18:02:31 [WARNING] loader.py:565, Writing unknown strains from GENOMICS data to /mnt/scratch/louwe015/NPLinker/own/nplinker_shared/nplinker_data/pairedomics/extracted/MSV000084771/unknown_strains_gen.csv\n",
      "18:02:31 [INFO] class_matches.py:44, Loaded MIBiG classes, and class matching tables\n",
      "18:02:31 [INFO] loader.py:623, Found CANOPUS dir, CANOPUS not run again!\n",
      "18:02:31 [INFO] chem_classes.py:191, reading canopus results for spectra from /mnt/scratch/louwe015/NPLinker/own/nplinker_shared/nplinker_data/pairedomics/extracted/MSV000084771/canopus/cluster_index_classifications.txt\n",
      "18:02:31 [INFO] chem_classes.py:499, reading molnetenhancer results from /mnt/scratch/louwe015/NPLinker/own/nplinker_shared/nplinker_data/pairedomics/extracted/MSV000084771/molnetenhancer\n",
      "18:02:31 [INFO] chem_classes.py:524, cf_kingdom\tcf_superclass\tcf_class\tcf_subclass\tcf_direct_parent\tcf_mframework\t0\n",
      "18:02:31 [INFO] chem_classes.py:524, cf_kingdom\tcf_superclass\tcf_class\tcf_subclass\tcf_direct_parent\tcf_mframework\t0\n",
      "18:02:31 [INFO] chem_classes.py:524, cf_kingdom\tcf_superclass\tcf_class\tcf_subclass\tcf_direct_parent\tcf_mframework\t0\n",
      "18:02:31 [INFO] chem_classes.py:524, cf_kingdom\tcf_superclass\tcf_class\tcf_subclass\tcf_direct_parent\tcf_mframework\t6\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b0c3bc219e76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'docker'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m      {'run_canopus': True}})\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mnpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/scratch/louwe015/NPLinker/nplinker/prototype/nplinker/nplinker.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(self, new_bigscape_cutoff, met_only)\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmet_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmet_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/scratch/louwe015/NPLinker/nplinker/prototype/nplinker/loader.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, met_only)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_class_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/scratch/louwe015/NPLinker/nplinker/prototype/nplinker/loader.py\u001b[0m in \u001b[0;36m_load_class_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m         chem_classes = ChemClassPredictions(\n\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanopus_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmolnetenhancer_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             self._root, should_run_canopus)\n\u001b[0m\u001b[1;32m    629\u001b[0m         \u001b[0;31m# if no molfam classes transfer them from spectra (due to old style MN)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchem_classes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanopus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmolfam_classes\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/scratch/louwe015/NPLinker/nplinker/prototype/nplinker/class_info/chem_classes.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, canopus_dir, mne_dir, gnps_dir, run_canopus)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \"\"\"\n\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_canopus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCanopusResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanopus_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgnps_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_canopus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_molnetenhancer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMolNetEnhancerResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmne_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mclass_predict_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/scratch/louwe015/NPLinker/nplinker/prototype/nplinker/class_info/chem_classes.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mne_dir)\u001b[0m\n\u001b[1;32m    459\u001b[0m         \"\"\"\n\u001b[1;32m    460\u001b[0m         cf_classes_names, molfam_classes, spectra2molfam = self._read_cf_classes(\n\u001b[0;32m--> 461\u001b[0;31m             mne_dir)\n\u001b[0m\u001b[1;32m    462\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spectra2molfam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspectra2molfam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_molfam_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmolfam_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/scratch/louwe015/NPLinker/nplinker/prototype/nplinker/class_info/chem_classes.py\u001b[0m in \u001b[0;36m_read_cf_classes\u001b[0;34m(self, mne_dir)\u001b[0m\n\u001b[1;32m    523\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cf_kingdom\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m                             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m                         \u001b[0mclass_tup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# load local crusemann data\n",
    "npl = NPLinker(\n",
    "    {'dataset':\n",
    "     {'root': '/mnt/scratch/louwe015/NPLinker/own/nplinker_shared/nplinker_data/pairedomics/extracted/MSV000084771/'},\n",
    "    'docker':\n",
    "     {'run_canopus': True}})\n",
    "npl.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic functionality\n",
    "# ===================\n",
    "#\n",
    "# Once you have an NPLinker object with all data loaded, there are a collection of simple\n",
    "# methods and properties you can use to access objects and metadata. Some examples are \n",
    "# given below, see https://nplinker.readthedocs.io/en/latest/ for a complete API description.\n",
    "\n",
    "# configuration/dataset metadata\n",
    "# - a copy of the configuration as parsed from the .toml file (dict)\n",
    "print(npl.config) \n",
    "# - the path to the directory where various nplinker data files are located (e.g. the \n",
    "#   default configuration file template) (str)\n",
    "print(npl.data_dir)\n",
    "# - a dataset ID, derived from the path for local datasets or the paired platform ID\n",
    "#   for datasets loaded from that source (str)\n",
    "print(npl.dataset_id)\n",
    "# - the root directory for the current dataset (str)\n",
    "print(npl.root_dir)\n",
    "\n",
    "# objects\n",
    "# - you can directly access lists of each of the 4 object types:\n",
    "print('BGCs:', len(npl.bgcs))\n",
    "print('GCFs:', len(npl.gcfs)) # contains GCF objects\n",
    "print('Spectra:', len(npl.spectra)) # contains Spectrum objects\n",
    "print('Molecular Families:', len(npl.molfams)) # contains MolecularFamily objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-andrews",
   "metadata": {},
   "source": [
    "## Scoring using the new NPClassScore method\n",
    "Use the scoring methods in NPLinker to find links with:\n",
    "- Metcalf scoring\n",
    "- Metcalf + NPClassScore scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-electric",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = npl.scoring_method('metcalf')\n",
    "\n",
    "# Now mc is an instance of the class that implements Metcalf scoring. Once\n",
    "# you have such an instance, you may change any of the parameters it exposes.\n",
    "# In the case of Metcalf scoring, the following parameters are currently exposed:\n",
    "# - cutoff (float): the scoring threshold. Links with scores less than this are excluded\n",
    "# - standardised (bool): set to True to use standardised scores (default), False for regular\n",
    "mc.cutoff = 2.5\n",
    "mc.standardised = True\n",
    "\n",
    "results = npl.get_links(npl.gcfs, mc, and_mode=True)\n",
    "\n",
    "# get_links returns an instance of a class called LinkCollection. This provides a wrapper\n",
    "# around the results of the scoring operation and has various useful properties/methods:\n",
    "#\n",
    "# - len(results) or .source_count will tell you how many of the input_objects were found to have links\n",
    "print('Number of results: {}'.format(len(results)))\n",
    "# - .sources is a list of those objects\n",
    "objects_with_links = results.sources\n",
    "# - .links is a dict with structure {input_object: {linked_object: ObjectLink}} \n",
    "objects_and_link_info = results.links\n",
    "# - .get_all_targets() will return a flat list of *all* the linked objects (for all sources)\n",
    "all_targets = results.get_all_targets() \n",
    "# - .methods is a list of the scoring methods passed to get_links\n",
    "methods = results.methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise NPClassScore scoring the same way\n",
    "# default method: 'mix' meaning use both CANOPUS and MolNetEnhancer with priority to CANOPUS\n",
    "npcl = npl.scoring_method('npclassscore')\n",
    "npcl.cutoff = 0.25\n",
    "\n",
    "# Now only links are kept that pass the cutoff for both methods\n",
    "results_both = npl.get_links(npl.gcfs, [mc, npcl], and_mode=True)\n",
    "\n",
    "print('Number of results for Metcalf and NPClassScore scoring: {}'.format(len(results_both)))\n",
    "print(results_both.methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also create an object with both Metcalf and NPClassScore with a cutoff of 0 to investigate proper cutoff\n",
    "npcl_0 = npl.scoring_method('npclassscore')\n",
    "npcl_0.cutoff = 0\n",
    "\n",
    "# Now only links are kept that pass the cutoff for both methods\n",
    "results_0 = npl.get_links(npl.gcfs, [mc, npcl_0], and_mode=True)\n",
    "\n",
    "print('Number of results for Metcalf and NPClassScore scoring: {}'.format(len(results_0)))\n",
    "print(results_0.methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_no_matches = 0\n",
    "for spec in npl.spectra:\n",
    "    spec_can = npl.chem_classes.canopus.spectra_classes.get(str(spec.spectrum_id))\n",
    "    if not spec_can:\n",
    "        spec_mne = npl.chem_classes.molnetenhancer.spectra_classes(str(spec.spectrum_id))\n",
    "        if spec_mne:\n",
    "            print(spec_mne)\n",
    "            if spec_mne[0][0] == 'no matches':\n",
    "                mne_no_matches += 1\n",
    "mne_no_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-search",
   "metadata": {},
   "source": [
    "## Investigating NPClassScore cutoff\n",
    "We choose 0.25 as a cutoff as around this value there is a marked drop in the number of links per GCF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-oxide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient of class linking score cutoff\n",
    "\n",
    "cs_cutoffs = [0.125, 0.25, 0.375, 0.5, 0.625, 0.75, 0.875]\n",
    "d_all_num_links = []\n",
    "d_all_num_filtered_links = {cut: [] for cut in cs_cutoffs}\n",
    "d_all_no_scores = []\n",
    "\n",
    "for gcf in npl.gcfs:\n",
    "    # filter out MF links\n",
    "    num_links = 0\n",
    "    if gcf in results.links:\n",
    "        num_links = len([link_data for link_data in results.get_sorted_links(mc, gcf)\n",
    "                         if isinstance(link_data.target, Spectrum)])\n",
    "    \n",
    "    # loop through cutoffs\n",
    "    for cs_cut in cs_cutoffs:\n",
    "        num_filtered_links = 0\n",
    "        if gcf in results_0.links:\n",
    "            # calculate number of links with npcl filtering\n",
    "            num_filtered_links = len([link_data for link_data in results_0.get_sorted_links(mc, gcf)\n",
    "                                      if isinstance(link_data.target, Spectrum) and \n",
    "                                      float(npcl_0.format_data(link_data[npcl_0])) > cs_cut])\n",
    "        d_all_num_filtered_links[cs_cut].append(num_filtered_links)\n",
    "    d_all_num_links.append(num_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-converter",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"NPClassScore_cutoff\\tNumber_of_links\\tChange\")\n",
    "print(f\"0\\t{np.mean(d_all_num_links):.2f}\")\n",
    "for cs_cut, filt_links in d_all_num_filtered_links.items():\n",
    "    print(f\"{cs_cut}\\t{np.mean(filt_links):.2f}\\t{(np.mean(filt_links)-np.mean(d_all_num_links))/np.mean(d_all_num_links):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-robertson",
   "metadata": {},
   "source": [
    "## Counting number of links\n",
    "For each GCF count the number of links with and without NPClassScore filtering using the chosen cutoff of 0.25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-rescue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all gcfs (objects) and count how many links exist (spectra)\n",
    "all_num_links = []\n",
    "all_num_filtered_links = []\n",
    "all_no_scores = []\n",
    "\n",
    "for gcf in npl.gcfs:\n",
    "    # filter out MF links\n",
    "    num_links = 0\n",
    "    if gcf in results.links:\n",
    "        num_links = len([link_data for link_data in results.get_sorted_links(mc, gcf)\n",
    "                         if isinstance(link_data.target, Spectrum)])\n",
    "    num_filtered_links = 0\n",
    "    if gcf in results_both.links:\n",
    "        num_filtered_links = len([link_data for link_data in results_both.get_sorted_links(mc, gcf)\n",
    "                                  if isinstance(link_data.target, Spectrum)])\n",
    "    all_num_links.append(num_links)\n",
    "    all_num_filtered_links.append(num_filtered_links)\n",
    "\n",
    "np.mean(all_num_links), np.mean(all_num_filtered_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-george",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change in average links per GCF\n",
    "(np.mean(all_num_filtered_links)-np.mean(all_num_links))/np.mean(all_num_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-latin",
   "metadata": {},
   "source": [
    "## Making plots showing the filtered links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-chapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_filt_items = sorted(d_all_num_filtered_links.items())\n",
    "labels = [\"0\"] + [f\"{cut}\" for cut, vals in sorted_filt_items]\n",
    "xs = [d_all_num_links] + [vals for keys, vals in sorted_filt_items]\n",
    "lg_size = 14\n",
    "custom_xlim = (-1, max(d_all_num_links))\n",
    "links_title = \"Number of links per GCF\"\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(14, 8))\n",
    "ax.boxplot(xs, labels=labels, flierprops={\"markersize\": 0.5}, medianprops={\"color\": \"black\"})\n",
    "plt.setp(ax, ylim=custom_xlim, xlabel=\"Cutoffs NPClassScore\", ylabel=links_title)\n",
    "figout = \"/home/louwe015/NPLinker/boxplot_cutoffs_MSV000084771_npclass_mix_can-mne_figure.svg\"\n",
    "plt.savefig(figout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-meeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Use MNE when there is no CANOPUS prediction\")\n",
    "labels = [\"Links\", \"Filtered links\"]\n",
    "colours = [\"#003f5c\", \"#bc5090\", \"#ffa600\"]\n",
    "xs = [all_num_links, all_num_filtered_links]\n",
    "lg_size = 14\n",
    "custom_xlim = (-1, max(d_all_num_links))\n",
    "bin_size = 25\n",
    "print(\"Bin size:\", bin_size)\n",
    "n_bins = np.arange(0, max(d_all_num_links), bin_size)\n",
    "links_title = \"Number of links per GCF\"\n",
    "count_title = \"GCF counts\"\n",
    "hist_type = \"stepfilled\"\n",
    "alpha = 0.75\n",
    "\n",
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = 16\n",
    "BIGGER_SIZE = 18\n",
    "\n",
    "plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "# plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "fig, ax0 = plt.subplots(nrows=1, ncols=1, figsize=(7, 6))\n",
    "ax0.hist(xs[:2], bins=n_bins, density=False, histtype=hist_type, stacked=False, label=labels[:2],\n",
    "         color=colours[:2], alpha=alpha)\n",
    "ax0.legend(prop={'size': lg_size})\n",
    "plt.setp(ax0, xlim=custom_xlim, xlabel=links_title, ylabel=count_title)\n",
    "figout = \"/home/louwe015/NPLinker/filtered_links_MSV000084771_mix_can-mne_figure_new.svg\"\n",
    "plt.savefig(figout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-custody",
   "metadata": {},
   "source": [
    "## Investigate known links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-empire",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_links_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-philip",
   "metadata": {},
   "source": [
    "### Staurosporine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-moldova",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the right GCF by seeing if this mibig occurs in the knownclusterblast results\n",
    "key = 'bgc0000827'\n",
    "result_bgcs = defaultdict(list)\n",
    "interest_lines = []\n",
    "for bgc in npl.bgcs:\n",
    "    as_file = bgc.antismash_file\n",
    "    with open(as_file) as inf:\n",
    "        for x in range(1000):\n",
    "            line = inf.readline().lower()\n",
    "            if key in line:\n",
    "                result_bgcs[bgc].append(line.strip())\n",
    "print(len(result_bgcs))\n",
    "result_gcfs = set([parent for bgc in result_bgcs for parent in bgc.parents])\n",
    "print(result_gcfs, len(result_gcfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-accreditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_hit = 'staurosporine'\n",
    "known_links_dict[name_hit] = {'hits': [], 'counts': None}\n",
    "spectrum_hits = [89513]  # based on library hits\n",
    "\n",
    "result_gcf = [gcf for gcf in npl.gcfs if gcf.id == 534][0]\n",
    "result_gcf, list(result_gcf.bgcs)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-accident",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 0.25\n",
    "result_links_both = results_both.links[result_gcf]\n",
    "result_links_mc = results.get_sorted_links(mc, result_gcf)\n",
    "count = 0\n",
    "i = 0\n",
    "show_x = 10\n",
    "include_below_cutoff = False\n",
    "prev_mc = 10**100\n",
    "delay = 0\n",
    "print('Results for object: {}, {} total links, {} methods used'.format(result_gcf, len(result_links_both), results.method_count))\n",
    "print(\"Rank above cutoff (original rank)\")\n",
    "for link_data in result_links_mc:\n",
    "    if count == show_x:\n",
    "        break\n",
    "    if isinstance(link_data.target, Spectrum):\n",
    "        link_data_both = result_links_both.get(link_data.target)\n",
    "        cur_mc = link_data[mc]\n",
    "        i += 1\n",
    "        \n",
    "        pref = 'x.'\n",
    "        cl_score = None\n",
    "        if link_data_both:\n",
    "            cl_score = link_data_both[npcl]\n",
    "            if cl_score[0][0] > cutoff:\n",
    "                if cur_mc < prev_mc:\n",
    "                    count += 1\n",
    "                    count += delay\n",
    "                    delay = 0\n",
    "                else:\n",
    "                    delay += 1\n",
    "                pref = f\"{count}.\"\n",
    "                prev_mc = cur_mc\n",
    "        if include_below_cutoff or not pref == 'x.':\n",
    "            print('{}({})\\t{}\\t{}={}\\tshared strains={}\\tMF={}'.format(\n",
    "                pref,\n",
    "                i,\n",
    "                link_data.target,\n",
    "                ','.join(method.name for method in link_data.methods),\n",
    "                mc.format_data(cur_mc),\n",
    "                len(link_data.shared_strains),\n",
    "                link_data.target.family_id))\n",
    "            if cl_score:\n",
    "                print('NPClassScore:', cl_score[0])\n",
    "            comp_name = ''\n",
    "            if link_data.target.gnps_annotations:\n",
    "                comp_name = link_data.target.gnps_annotations.get(\"Compound_Name\")\n",
    "                print('Library match:', comp_name)\n",
    "            print('Precursor_mz:', link_data.target.precursor_mz)\n",
    "            if link_data.target.spectrum_id in spectrum_hits or name_hit in comp_name.lower():\n",
    "                print(\"--MATCH--\")\n",
    "                known_links_dict[name_hit]['hits'].append((count, i, result_gcf, link_data))\n",
    "    if count + delay == show_x:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-content",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_counts = 0\n",
    "metcalf_counts = 0\n",
    "for link_data in result_links_mc:\n",
    "    if isinstance(link_data.target, Spectrum):\n",
    "        metcalf_counts += 1\n",
    "        link_data_both = result_links_both.get(link_data.target)\n",
    "        if link_data_both:\n",
    "            cl_score = link_data_both[npcl]\n",
    "            if cl_score[0][0] > cutoff:\n",
    "                filtered_counts += 1\n",
    "known_links_dict[name_hit]['counts'] = (metcalf_counts, filtered_counts)\n",
    "print(metcalf_counts, filtered_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-trading",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
