{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, csv, os\n",
    "# if running from clone of the git repo\n",
    "sys.path.append('../prototype')\n",
    "\n",
    "# import the main NPLinker class. normally this all that's required to work\n",
    "# with NPLinker in a notebook environment\n",
    "from nplinker.nplinker import NPLinker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:53:43 [INFO] config.py:117, Selected platform project ID MSV000079284\n",
      "14:53:43 [INFO] downloader.py:159, Downloader for MSV000079284, caching to /home/louwe015/nplinker_data/pairedomics\n",
      "14:53:43 [INFO] downloader.py:162, Downloading new copy of platform project data...\n",
      "14:53:43 [INFO] downloader.py:188, Found project, retrieving JSON data...\n"
     ]
    }
   ],
   "source": [
    "# the standard method of loading a dataset configuration is to pass the filename\n",
    "# of a TOML configuration file to the NPLinker constructor.\n",
    "# toml_file = 'nplinker_demo1_crus.toml'\n",
    "npl = NPLinker({'dataset': {'root':\"platform:MSV000079284\"}})\n",
    "# loading the actual data files can take some time depending on the dataset,\n",
    "# so this is done separately by calling the load_data method.\n",
    "#\n",
    "# During the loading process, logging messages will be printed to stdout. This\n",
    "# can be useful for debugging problems with files not being discovered or parsed\n",
    "# correctly. You can control the verbosity of these messages in the configuration\n",
    "# file if required, and/or redirect them to a file instead of stdout. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:53:47 [INFO] downloader.py:213, Going to download the metabolomics data file\n",
      "14:53:47 [INFO] downloader.py:634, Downloading metabolomics data from https://gnps.ucsd.edu/ProteoSAFe/DownloadResult?task=c22f44b14a3d450eb836d607cb9521bb&view=download_clustered_spectra\n",
      "14:53:56 [INFO] downloader.py:646, Downloaded metabolomics data!\n",
      "14:53:56 [INFO] downloader.py:651, Extracting files to /home/louwe015/nplinker_data/pairedomics/extracted/MSV000079284\n",
      "14:53:58 [INFO] downloader.py:676, Found OLD GNPS structure\n",
      "14:53:58 [INFO] downloader.py:390, Checking for antismash data 1/28, current genome ID=GCF_000515175.1\n",
      "14:53:58 [INFO] downloader.py:405, Beginning lookup process for genome ID GCF_000515175.1\n",
      "14:53:58 [INFO] downloader.py:458, antismash DB lookup for GCF_000515175.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000515175.1/\n",
      "14:53:58 [INFO] downloader.py:458, antismash DB lookup for GCF_000515175.1.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000515175.1.1/\n",
      "14:53:59 [INFO] downloader.py:458, antismash DB lookup for GCF_000515175.1 => https://antismash-dbv2.secondarymetabolites.org/output/GCF_000515175.1/\n",
      "14:53:59 [INFO] downloader.py:458, antismash DB lookup for GCF_000515175.1.1 => https://antismash-dbv2.secondarymetabolites.org/output/GCF_000515175.1.1/\n",
      "14:53:59 [WARNING] downloader.py:422, Failed to download antiSMASH data for genome ID GCF_000515175.1 (GCF_000515175.1)\n",
      "14:53:59 [INFO] downloader.py:390, Checking for antismash data 2/28, current genome ID=GCF_000514635.1\n",
      "14:53:59 [INFO] downloader.py:405, Beginning lookup process for genome ID GCF_000514635.1\n",
      "14:53:59 [INFO] downloader.py:458, antismash DB lookup for GCF_000514635.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000514635.1/\n",
      "14:54:01 [INFO] downloader.py:468, antiSMASH lookup succeeded! Filename is GCF_000514635.1.zip\n",
      "14:54:02 [INFO] downloader.py:486, Downloading from antiSMASH: https://antismash-db.secondarymetabolites.org/output/GCF_000514635.1/GCF_000514635.1.zip\n",
      "14:54:04 [INFO] downloader.py:419, Genome data successfully downloaded for GCF_000514635.1\n",
      "14:54:06 [INFO] downloader.py:390, Checking for antismash data 3/28, current genome ID=GCF_000702345.1\n",
      "14:54:06 [INFO] downloader.py:405, Beginning lookup process for genome ID GCF_000702345.1\n",
      "14:54:06 [INFO] downloader.py:458, antismash DB lookup for GCF_000702345.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000702345.1/\n",
      "14:54:07 [INFO] downloader.py:458, antismash DB lookup for GCF_000702345.1.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000702345.1.1/\n",
      "14:54:07 [INFO] downloader.py:458, antismash DB lookup for GCF_000702345.1 => https://antismash-dbv2.secondarymetabolites.org/output/GCF_000702345.1/\n",
      "14:54:07 [INFO] downloader.py:458, antismash DB lookup for GCF_000702345.1.1 => https://antismash-dbv2.secondarymetabolites.org/output/GCF_000702345.1.1/\n",
      "14:54:07 [WARNING] downloader.py:422, Failed to download antiSMASH data for genome ID GCF_000702345.1 (GCF_000702345.1)\n",
      "14:54:07 [INFO] downloader.py:390, Checking for antismash data 4/28, current genome ID=GCF_000375025.1\n",
      "14:54:07 [INFO] downloader.py:405, Beginning lookup process for genome ID GCF_000375025.1\n",
      "14:54:07 [INFO] downloader.py:458, antismash DB lookup for GCF_000375025.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000375025.1/\n",
      "14:54:08 [INFO] downloader.py:458, antismash DB lookup for GCF_000375025.1.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000375025.1.1/\n",
      "14:54:08 [INFO] downloader.py:458, antismash DB lookup for GCF_000375025.1 => https://antismash-dbv2.secondarymetabolites.org/output/GCF_000375025.1/\n",
      "14:54:08 [INFO] downloader.py:458, antismash DB lookup for GCF_000375025.1.1 => https://antismash-dbv2.secondarymetabolites.org/output/GCF_000375025.1.1/\n",
      "14:54:08 [WARNING] downloader.py:422, Failed to download antiSMASH data for genome ID GCF_000375025.1 (GCF_000375025.1)\n",
      "14:54:08 [INFO] downloader.py:390, Checking for antismash data 5/28, current genome ID=GCF_000514975.1\n",
      "14:54:08 [INFO] downloader.py:405, Beginning lookup process for genome ID GCF_000514975.1\n",
      "14:54:08 [INFO] downloader.py:458, antismash DB lookup for GCF_000514975.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000514975.1/\n",
      "14:54:11 [INFO] downloader.py:468, antiSMASH lookup succeeded! Filename is GCF_000514975.1.zip\n",
      "14:54:11 [INFO] downloader.py:486, Downloading from antiSMASH: https://antismash-db.secondarymetabolites.org/output/GCF_000514975.1/GCF_000514975.1.zip\n",
      "14:54:14 [INFO] downloader.py:419, Genome data successfully downloaded for GCF_000514975.1\n",
      "14:54:17 [INFO] downloader.py:390, Checking for antismash data 6/28, current genome ID=GCF_000018265.1\n",
      "14:54:17 [INFO] downloader.py:405, Beginning lookup process for genome ID GCF_000018265.1\n",
      "14:54:17 [INFO] downloader.py:458, antismash DB lookup for GCF_000018265.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000018265.1/\n",
      "14:54:20 [INFO] downloader.py:468, antiSMASH lookup succeeded! Filename is GCF_000018265.1.zip\n",
      "14:54:20 [INFO] downloader.py:486, Downloading from antiSMASH: https://antismash-db.secondarymetabolites.org/output/GCF_000018265.1/GCF_000018265.1.zip\n",
      "14:54:29 [INFO] downloader.py:419, Genome data successfully downloaded for GCF_000018265.1\n",
      "14:54:32 [INFO] downloader.py:390, Checking for antismash data 7/28, current genome ID=GCF_000514895.1\n",
      "14:54:32 [INFO] downloader.py:405, Beginning lookup process for genome ID GCF_000514895.1\n",
      "14:54:32 [INFO] downloader.py:458, antismash DB lookup for GCF_000514895.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000514895.1/\n",
      "14:54:34 [INFO] downloader.py:468, antiSMASH lookup succeeded! Filename is GCF_000514895.1.zip\n",
      "14:54:35 [INFO] downloader.py:486, Downloading from antiSMASH: https://antismash-db.secondarymetabolites.org/output/GCF_000514895.1/GCF_000514895.1.zip\n",
      "14:54:38 [INFO] downloader.py:419, Genome data successfully downloaded for GCF_000514895.1\n",
      "14:54:40 [INFO] downloader.py:390, Checking for antismash data 8/28, current genome ID=GCF_000373825.1\n",
      "14:54:40 [INFO] downloader.py:405, Beginning lookup process for genome ID GCF_000373825.1\n",
      "14:54:40 [INFO] downloader.py:458, antismash DB lookup for GCF_000373825.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000373825.1/\n",
      "14:54:42 [INFO] downloader.py:468, antiSMASH lookup succeeded! Filename is GCF_000373825.1.zip\n",
      "14:54:42 [INFO] downloader.py:486, Downloading from antiSMASH: https://antismash-db.secondarymetabolites.org/output/GCF_000373825.1/GCF_000373825.1.zip\n",
      "14:54:45 [INFO] downloader.py:419, Genome data successfully downloaded for GCF_000373825.1\n",
      "14:54:47 [INFO] downloader.py:390, Checking for antismash data 9/28, current genome ID=GCF_000514875.1\n",
      "14:54:47 [INFO] downloader.py:405, Beginning lookup process for genome ID GCF_000514875.1\n",
      "14:54:47 [INFO] downloader.py:458, antismash DB lookup for GCF_000514875.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000514875.1/\n",
      "14:54:50 [INFO] downloader.py:468, antiSMASH lookup succeeded! Filename is GCF_000514875.1.zip\n",
      "14:54:50 [INFO] downloader.py:486, Downloading from antiSMASH: https://antismash-db.secondarymetabolites.org/output/GCF_000514875.1/GCF_000514875.1.zip\n",
      "14:54:52 [INFO] downloader.py:419, Genome data successfully downloaded for GCF_000514875.1\n",
      "14:54:55 [INFO] downloader.py:390, Checking for antismash data 10/28, current genome ID=GCF_000514755.1\n",
      "14:54:55 [INFO] downloader.py:405, Beginning lookup process for genome ID GCF_000514755.1\n",
      "14:54:55 [INFO] downloader.py:458, antismash DB lookup for GCF_000514755.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000514755.1/\n",
      "14:54:55 [INFO] downloader.py:458, antismash DB lookup for GCF_000514755.1.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000514755.1.1/\n",
      "14:54:55 [INFO] downloader.py:458, antismash DB lookup for GCF_000514755.1 => https://antismash-dbv2.secondarymetabolites.org/output/GCF_000514755.1/\n",
      "14:54:55 [INFO] downloader.py:458, antismash DB lookup for GCF_000514755.1.1 => https://antismash-dbv2.secondarymetabolites.org/output/GCF_000514755.1.1/\n",
      "14:54:56 [WARNING] downloader.py:422, Failed to download antiSMASH data for genome ID GCF_000514755.1 (GCF_000514755.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:54:56 [INFO] downloader.py:390, Checking for antismash data 11/28, current genome ID=GCF_000514775.1\n",
      "14:54:56 [INFO] downloader.py:405, Beginning lookup process for genome ID GCF_000514775.1\n",
      "14:54:56 [INFO] downloader.py:458, antismash DB lookup for GCF_000514775.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000514775.1/\n",
      "14:54:58 [INFO] downloader.py:468, antiSMASH lookup succeeded! Filename is GCF_000514775.1.zip\n",
      "14:54:58 [INFO] downloader.py:486, Downloading from antiSMASH: https://antismash-db.secondarymetabolites.org/output/GCF_000514775.1/GCF_000514775.1.zip\n",
      "14:55:01 [INFO] downloader.py:419, Genome data successfully downloaded for GCF_000514775.1\n",
      "14:55:03 [INFO] downloader.py:390, Checking for antismash data 12/28, current genome ID=GCF_000374665.1\n",
      "14:55:03 [INFO] downloader.py:405, Beginning lookup process for genome ID GCF_000374665.1\n",
      "14:55:03 [INFO] downloader.py:458, antismash DB lookup for GCF_000374665.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000374665.1/\n",
      "14:55:05 [INFO] downloader.py:468, antiSMASH lookup succeeded! Filename is GCF_000374665.1.zip\n",
      "14:55:05 [INFO] downloader.py:486, Downloading from antiSMASH: https://antismash-db.secondarymetabolites.org/output/GCF_000374665.1/GCF_000374665.1.zip\n",
      "14:55:08 [INFO] downloader.py:419, Genome data successfully downloaded for GCF_000374665.1\n",
      "14:55:09 [INFO] downloader.py:390, Checking for antismash data 13/28, current genome ID=GCF_000374685.1\n",
      "14:55:09 [INFO] downloader.py:405, Beginning lookup process for genome ID GCF_000374685.1\n",
      "14:55:09 [INFO] downloader.py:458, antismash DB lookup for GCF_000374685.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000374685.1/\n",
      "14:55:11 [INFO] downloader.py:468, antiSMASH lookup succeeded! Filename is GCF_000374685.1.zip\n",
      "14:55:12 [INFO] downloader.py:486, Downloading from antiSMASH: https://antismash-db.secondarymetabolites.org/output/GCF_000374685.1/GCF_000374685.1.zip\n",
      "14:55:14 [INFO] downloader.py:419, Genome data successfully downloaded for GCF_000374685.1\n",
      "14:55:16 [INFO] downloader.py:390, Checking for antismash data 14/28, current genome ID=GCF_000424905.1\n",
      "14:55:16 [INFO] downloader.py:405, Beginning lookup process for genome ID GCF_000424905.1\n",
      "14:55:16 [INFO] downloader.py:458, antismash DB lookup for GCF_000424905.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000424905.1/\n",
      "14:55:18 [INFO] downloader.py:468, antiSMASH lookup succeeded! Filename is GCF_000424905.1.zip\n",
      "14:55:18 [INFO] downloader.py:486, Downloading from antiSMASH: https://antismash-db.secondarymetabolites.org/output/GCF_000424905.1/GCF_000424905.1.zip\n",
      "14:55:21 [INFO] downloader.py:419, Genome data successfully downloaded for GCF_000424905.1\n",
      "14:55:23 [INFO] downloader.py:390, Checking for antismash data 15/28, current genome ID=GCF_000374725.1\n",
      "14:55:23 [INFO] downloader.py:405, Beginning lookup process for genome ID GCF_000374725.1\n",
      "14:55:23 [INFO] downloader.py:458, antismash DB lookup for GCF_000374725.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000374725.1/\n",
      "14:55:24 [INFO] downloader.py:458, antismash DB lookup for GCF_000374725.1.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000374725.1.1/\n",
      "14:55:24 [INFO] downloader.py:458, antismash DB lookup for GCF_000374725.1 => https://antismash-dbv2.secondarymetabolites.org/output/GCF_000374725.1/\n",
      "14:55:24 [INFO] downloader.py:458, antismash DB lookup for GCF_000374725.1.1 => https://antismash-dbv2.secondarymetabolites.org/output/GCF_000374725.1.1/\n",
      "14:55:24 [WARNING] downloader.py:422, Failed to download antiSMASH data for genome ID GCF_000374725.1 (GCF_000374725.1)\n",
      "14:55:24 [INFO] downloader.py:390, Checking for antismash data 16/28, current genome ID=GCF_000514575.1\n",
      "14:55:24 [INFO] downloader.py:405, Beginning lookup process for genome ID GCF_000514575.1\n",
      "14:55:24 [INFO] downloader.py:458, antismash DB lookup for GCF_000514575.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000514575.1/\n",
      "14:55:24 [INFO] downloader.py:458, antismash DB lookup for GCF_000514575.1.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000514575.1.1/\n",
      "14:55:25 [INFO] downloader.py:458, antismash DB lookup for GCF_000514575.1 => https://antismash-dbv2.secondarymetabolites.org/output/GCF_000514575.1/\n",
      "14:55:25 [INFO] downloader.py:458, antismash DB lookup for GCF_000514575.1.1 => https://antismash-dbv2.secondarymetabolites.org/output/GCF_000514575.1.1/\n",
      "14:55:25 [WARNING] downloader.py:422, Failed to download antiSMASH data for genome ID GCF_000514575.1 (GCF_000514575.1)\n",
      "14:55:25 [INFO] downloader.py:390, Checking for antismash data 17/28, current genome ID=GCF_000514515.1\n",
      "14:55:25 [INFO] downloader.py:405, Beginning lookup process for genome ID GCF_000514515.1\n",
      "14:55:25 [INFO] downloader.py:458, antismash DB lookup for GCF_000514515.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000514515.1/\n",
      "14:55:27 [INFO] downloader.py:468, antiSMASH lookup succeeded! Filename is GCF_000514515.1.zip\n",
      "14:55:27 [INFO] downloader.py:486, Downloading from antiSMASH: https://antismash-db.secondarymetabolites.org/output/GCF_000514515.1/GCF_000514515.1.zip\n",
      "14:55:29 [INFO] downloader.py:419, Genome data successfully downloaded for GCF_000514515.1\n",
      "14:55:30 [INFO] downloader.py:390, Checking for antismash data 18/28, current genome ID=GCF_000514455.1\n",
      "14:55:30 [INFO] downloader.py:405, Beginning lookup process for genome ID GCF_000514455.1\n",
      "14:55:30 [INFO] downloader.py:458, antismash DB lookup for GCF_000514455.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000514455.1/\n",
      "14:55:31 [INFO] downloader.py:458, antismash DB lookup for GCF_000514455.1.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000514455.1.1/\n",
      "14:55:31 [INFO] downloader.py:458, antismash DB lookup for GCF_000514455.1 => https://antismash-dbv2.secondarymetabolites.org/output/GCF_000514455.1/\n",
      "14:55:31 [INFO] downloader.py:458, antismash DB lookup for GCF_000514455.1.1 => https://antismash-dbv2.secondarymetabolites.org/output/GCF_000514455.1.1/\n",
      "14:55:31 [WARNING] downloader.py:422, Failed to download antiSMASH data for genome ID GCF_000514455.1 (GCF_000514455.1)\n",
      "14:55:31 [INFO] downloader.py:390, Checking for antismash data 19/28, current genome ID=GCF_000514675.1\n",
      "14:55:31 [INFO] downloader.py:405, Beginning lookup process for genome ID GCF_000514675.1\n",
      "14:55:31 [INFO] downloader.py:458, antismash DB lookup for GCF_000514675.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000514675.1/\n",
      "14:55:32 [INFO] downloader.py:458, antismash DB lookup for GCF_000514675.1.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000514675.1.1/\n",
      "14:55:32 [INFO] downloader.py:458, antismash DB lookup for GCF_000514675.1 => https://antismash-dbv2.secondarymetabolites.org/output/GCF_000514675.1/\n",
      "14:55:32 [INFO] downloader.py:458, antismash DB lookup for GCF_000514675.1.1 => https://antismash-dbv2.secondarymetabolites.org/output/GCF_000514675.1.1/\n",
      "14:55:32 [WARNING] downloader.py:422, Failed to download antiSMASH data for genome ID GCF_000514675.1 (GCF_000514675.1)\n",
      "14:55:32 [INFO] downloader.py:390, Checking for antismash data 20/28, current genome ID=GCF_000514435.1\n",
      "14:55:32 [INFO] downloader.py:405, Beginning lookup process for genome ID GCF_000514435.1\n",
      "14:55:32 [INFO] downloader.py:458, antismash DB lookup for GCF_000514435.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000514435.1/\n",
      "14:55:33 [INFO] downloader.py:458, antismash DB lookup for GCF_000514435.1.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000514435.1.1/\n",
      "14:55:33 [INFO] downloader.py:458, antismash DB lookup for GCF_000514435.1 => https://antismash-dbv2.secondarymetabolites.org/output/GCF_000514435.1/\n",
      "14:55:33 [INFO] downloader.py:458, antismash DB lookup for GCF_000514435.1.1 => https://antismash-dbv2.secondarymetabolites.org/output/GCF_000514435.1.1/\n",
      "14:55:33 [WARNING] downloader.py:422, Failed to download antiSMASH data for genome ID GCF_000514435.1 (GCF_000514435.1)\n",
      "14:55:34 [INFO] downloader.py:390, Checking for antismash data 21/28, current genome ID=GCF_000375285.1\n",
      "14:55:34 [INFO] downloader.py:405, Beginning lookup process for genome ID GCF_000375285.1\n",
      "14:55:34 [INFO] downloader.py:458, antismash DB lookup for GCF_000375285.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000375285.1/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:55:34 [INFO] downloader.py:458, antismash DB lookup for GCF_000375285.1.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000375285.1.1/\n",
      "14:55:34 [INFO] downloader.py:458, antismash DB lookup for GCF_000375285.1 => https://antismash-dbv2.secondarymetabolites.org/output/GCF_000375285.1/\n",
      "14:55:34 [INFO] downloader.py:458, antismash DB lookup for GCF_000375285.1.1 => https://antismash-dbv2.secondarymetabolites.org/output/GCF_000375285.1.1/\n",
      "14:55:35 [WARNING] downloader.py:422, Failed to download antiSMASH data for genome ID GCF_000375285.1 (GCF_000375285.1)\n",
      "14:55:35 [INFO] downloader.py:390, Checking for antismash data 22/28, current genome ID=GCF_000514855.1\n",
      "14:55:35 [INFO] downloader.py:405, Beginning lookup process for genome ID GCF_000514855.1\n",
      "14:55:35 [INFO] downloader.py:458, antismash DB lookup for GCF_000514855.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000514855.1/\n",
      "14:55:36 [INFO] downloader.py:468, antiSMASH lookup succeeded! Filename is GCF_000514855.1.zip\n",
      "14:55:37 [INFO] downloader.py:486, Downloading from antiSMASH: https://antismash-db.secondarymetabolites.org/output/GCF_000514855.1/GCF_000514855.1.zip\n",
      "14:55:39 [INFO] downloader.py:419, Genome data successfully downloaded for GCF_000514855.1\n",
      "14:55:41 [INFO] downloader.py:390, Checking for antismash data 23/28, current genome ID=GCF_000484695.1\n",
      "14:55:41 [INFO] downloader.py:405, Beginning lookup process for genome ID GCF_000484695.1\n",
      "14:55:41 [INFO] downloader.py:458, antismash DB lookup for GCF_000484695.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000484695.1/\n",
      "14:55:41 [INFO] downloader.py:458, antismash DB lookup for GCF_000484695.1.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000484695.1.1/\n",
      "14:55:41 [INFO] downloader.py:458, antismash DB lookup for GCF_000484695.1 => https://antismash-dbv2.secondarymetabolites.org/output/GCF_000484695.1/\n",
      "14:55:41 [INFO] downloader.py:458, antismash DB lookup for GCF_000484695.1.1 => https://antismash-dbv2.secondarymetabolites.org/output/GCF_000484695.1.1/\n",
      "14:55:42 [WARNING] downloader.py:422, Failed to download antiSMASH data for genome ID GCF_000484695.1 (GCF_000484695.1)\n",
      "14:55:42 [INFO] downloader.py:390, Checking for antismash data 24/28, current genome ID=GCF_000377025.1\n",
      "14:55:42 [INFO] downloader.py:405, Beginning lookup process for genome ID GCF_000377025.1\n",
      "14:55:42 [INFO] downloader.py:458, antismash DB lookup for GCF_000377025.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000377025.1/\n",
      "14:55:42 [INFO] downloader.py:458, antismash DB lookup for GCF_000377025.1.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000377025.1.1/\n",
      "14:55:42 [INFO] downloader.py:458, antismash DB lookup for GCF_000377025.1 => https://antismash-dbv2.secondarymetabolites.org/output/GCF_000377025.1/\n",
      "14:55:42 [INFO] downloader.py:458, antismash DB lookup for GCF_000377025.1.1 => https://antismash-dbv2.secondarymetabolites.org/output/GCF_000377025.1.1/\n",
      "14:55:43 [WARNING] downloader.py:422, Failed to download antiSMASH data for genome ID GCF_000377025.1 (GCF_000377025.1)\n",
      "14:55:43 [INFO] downloader.py:390, Checking for antismash data 25/28, current genome ID=GCF_000016425.1\n",
      "14:55:43 [INFO] downloader.py:405, Beginning lookup process for genome ID GCF_000016425.1\n",
      "14:55:43 [INFO] downloader.py:458, antismash DB lookup for GCF_000016425.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000016425.1/\n",
      "14:55:45 [INFO] downloader.py:468, antiSMASH lookup succeeded! Filename is GCF_000016425.1.zip\n",
      "14:55:45 [INFO] downloader.py:486, Downloading from antiSMASH: https://antismash-db.secondarymetabolites.org/output/GCF_000016425.1/GCF_000016425.1.zip\n",
      "14:55:52 [INFO] downloader.py:419, Genome data successfully downloaded for GCF_000016425.1\n",
      "14:55:53 [INFO] downloader.py:390, Checking for antismash data 26/28, current genome ID=GCF_000515075.1\n",
      "14:55:53 [INFO] downloader.py:405, Beginning lookup process for genome ID GCF_000515075.1\n",
      "14:55:53 [INFO] downloader.py:458, antismash DB lookup for GCF_000515075.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000515075.1/\n",
      "14:55:54 [INFO] downloader.py:458, antismash DB lookup for GCF_000515075.1.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000515075.1.1/\n",
      "14:55:54 [INFO] downloader.py:458, antismash DB lookup for GCF_000515075.1 => https://antismash-dbv2.secondarymetabolites.org/output/GCF_000515075.1/\n",
      "14:55:54 [INFO] downloader.py:458, antismash DB lookup for GCF_000515075.1.1 => https://antismash-dbv2.secondarymetabolites.org/output/GCF_000515075.1.1/\n",
      "14:55:54 [WARNING] downloader.py:422, Failed to download antiSMASH data for genome ID GCF_000515075.1 (GCF_000515075.1)\n",
      "14:55:54 [INFO] downloader.py:390, Checking for antismash data 27/28, current genome ID=GCF_000514695.1\n",
      "14:55:54 [INFO] downloader.py:405, Beginning lookup process for genome ID GCF_000514695.1\n",
      "14:55:54 [INFO] downloader.py:458, antismash DB lookup for GCF_000514695.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000514695.1/\n",
      "14:55:56 [INFO] downloader.py:468, antiSMASH lookup succeeded! Filename is GCF_000514695.1.zip\n",
      "14:55:56 [INFO] downloader.py:486, Downloading from antiSMASH: https://antismash-db.secondarymetabolites.org/output/GCF_000514695.1/GCF_000514695.1.zip\n",
      "14:55:59 [INFO] downloader.py:419, Genome data successfully downloaded for GCF_000514695.1\n",
      "14:56:00 [INFO] downloader.py:390, Checking for antismash data 28/28, current genome ID=GCF_000620325.1\n",
      "14:56:00 [INFO] downloader.py:405, Beginning lookup process for genome ID GCF_000620325.1\n",
      "14:56:00 [INFO] downloader.py:458, antismash DB lookup for GCF_000620325.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000620325.1/\n",
      "14:56:01 [INFO] downloader.py:458, antismash DB lookup for GCF_000620325.1.1 => https://antismash-db.secondarymetabolites.org/output/GCF_000620325.1.1/\n",
      "14:56:01 [INFO] downloader.py:458, antismash DB lookup for GCF_000620325.1 => https://antismash-dbv2.secondarymetabolites.org/output/GCF_000620325.1/\n",
      "14:56:01 [INFO] downloader.py:458, antismash DB lookup for GCF_000620325.1.1 => https://antismash-dbv2.secondarymetabolites.org/output/GCF_000620325.1.1/\n",
      "14:56:01 [WARNING] downloader.py:422, Failed to download antiSMASH data for genome ID GCF_000620325.1 (GCF_000620325.1)\n",
      "14:56:01 [INFO] downloader.py:430, Dataset has 14 missing sets of antiSMASH data (from a total of 28)\n",
      "14:56:01 [WARNING] downloader.py:602, Failed to extract accession from genome with label Salinispora arenicola CNB527\n",
      "14:56:01 [WARNING] downloader.py:602, Failed to extract accession from genome with label Salinispora arenicola CNH996\n",
      "14:56:01 [WARNING] downloader.py:602, Failed to extract accession from genome with label Salinispora arenicola CNP193\n",
      "14:56:01 [WARNING] downloader.py:602, Failed to extract accession from genome with label Salinispora pacifica CNR894\n",
      "14:56:01 [WARNING] downloader.py:602, Failed to extract accession from genome with label Salinispora pacifica CNS863\n",
      "14:56:01 [WARNING] downloader.py:602, Failed to extract accession from genome with label Salinispora pacifica CNT003\n",
      "14:56:01 [WARNING] downloader.py:602, Failed to extract accession from genome with label Salinispora pacifica CNT138\n",
      "14:56:01 [WARNING] downloader.py:602, Failed to extract accession from genome with label Salinispora pacifica CNT148\n",
      "14:56:01 [WARNING] downloader.py:602, Failed to extract accession from genome with label Salinispora pacifica CNT150\n",
      "14:56:01 [WARNING] downloader.py:602, Failed to extract accession from genome with label Salinispora pacifica CNT851\n",
      "14:56:01 [WARNING] downloader.py:602, Failed to extract accession from genome with label Salinispora pacifica CNY202\n",
      "14:56:01 [WARNING] downloader.py:602, Failed to extract accession from genome with label Salinispora pacifica CNY330\n",
      "14:56:01 [WARNING] downloader.py:602, Failed to extract accession from genome with label Salinispora tropica CNB536\n",
      "14:56:01 [WARNING] downloader.py:602, Failed to extract accession from genome with label Salinispora tropica CNY012\n",
      "14:56:01 [INFO] downloader.py:611, Extracted 27 strains from JSON (met=48, gen=0)\n",
      "14:56:01 [INFO] downloader.py:116, Generating strain mappings file\n",
      "14:56:02 [INFO] downloader.py:133, Saving strains to /home/louwe015/nplinker_data/pairedomics/extracted/MSV000079284/strain_mappings.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:56:51 [INFO] downloader.py:233, Running BiG-SCAPE! extra_bigscape_parameters=\"\"\n",
      "14:56:51 [INFO] runbigscape.py:27, run_bigscape: input=\"/home/louwe015/nplinker_data/pairedomics/extracted/MSV000079284/antismash\", output=\"/home/louwe015/nplinker_data/pairedomics/extracted/MSV000079284/bigscape\", extra_params=\"\n",
      "14:56:51 [WARNING] downloader.py:237, Failed to run BiG-SCAPE on antismash data, error was \"Failed to find/run bigscape.py (path=/app/BiG-SCAPE/bigscape.py, err=[Errno 2] No such file or directory: '/app/BiG-SCAPE/bigscape.py': '/app/BiG-SCAPE/bigscape.py')\"\n",
      "14:56:51 [WARNING] loader.py:46, WARNING: unable to find extra_nodes_file in path \"/home/louwe015/nplinker_data/pairedomics/extracted/MSV000079284/quantification_table_reformatted/*.csv\"\n",
      "14:56:51 [WARNING] loader.py:46, WARNING: unable to find metadata_table_file in path \"/home/louwe015/nplinker_data/pairedomics/extracted/MSV000079284/metadata_table/metadata_table*.txt\"\n",
      "14:56:51 [WARNING] loader.py:46, WARNING: unable to find quantification_table_file in path \"/home/louwe015/nplinker_data/pairedomics/extracted/MSV000079284/quantification_table/quantification_table*.csv\"\n",
      "14:56:51 [INFO] loader.py:80, Trying to discover correct bigscape directory under /home/louwe015/nplinker_data/pairedomics/extracted/MSV000079284/bigscape\n",
      "14:56:51 [INFO] loader.py:571, Loaded global strain IDs (0 total)\n",
      "14:56:51 [INFO] loader.py:582, Loaded dataset strain IDs (27 total)\n",
      "14:57:09 [INFO] metabolomics.py:699, 25935 molecules parsed from MGF file\n",
      "14:57:15 [INFO] metabolomics.py:716, Found older-style GNPS dataset, no quantification table\n",
      "14:57:15 [WARNING] metabolomics.py:516, Unknown strain:  for cluster index 11542\n",
      "14:57:15 [WARNING] metabolomics.py:516, Unknown strain: 6b.mzXML for cluster index 5988\n",
      "14:57:15 [WARNING] metabolomics.py:516, Unknown strain: 6a.mzXML for cluster index 20258\n",
      "14:57:17 [WARNING] metabolomics.py:531, 3 unknown strains were detected a total of 27241 times\n",
      "14:57:17 [WARNING] loader.py:550, Writing unknown strains from METABOLOMICS data to /home/louwe015/nplinker_data/pairedomics/extracted/MSV000079284/unknown_strains_met.csv\n",
      "14:57:17 [INFO] loader.py:557, Loading provided annotation files (/home/louwe015/nplinker_data/pairedomics/extracted/MSV000079284/result_specnets_DB)\n",
      "14:57:18 [INFO] genomics.py:461, Found 1816 MiBIG json files\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Failed to find *any* BiGSCAPE Network_Annotations tsv files under \"/home/louwe015/nplinker_data/pairedomics/extracted/MSV000079284/bigscape\" (incorrect cutoff value? currently set to 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7c18820009e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/scratch/louwe015/NPLinker/nplinker/prototype/nplinker/nplinker.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(self, new_bigscape_cutoff, met_only)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmet_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmet_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/scratch/louwe015/NPLinker/nplinker/prototype/nplinker/loader.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, met_only)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmet_only\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_genomics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/scratch/louwe015/NPLinker/nplinker/prototype/nplinker/loader.py\u001b[0m in \u001b[0;36m_load_genomics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;31m# no files found here indicates a problem!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manno_files\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Failed to find *any* BiGSCAPE Network_Annotations tsv files under \"{}\" (incorrect cutoff value? currently set to {})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigscape_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bigscape_cutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_list_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Failed to find *any* BiGSCAPE Network_Annotations tsv files under \"/home/louwe015/nplinker_data/pairedomics/extracted/MSV000079284/bigscape\" (incorrect cutoff value? currently set to 30)"
     ]
    }
   ],
   "source": [
    "npl.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic functionality\n",
    "# ===================\n",
    "#\n",
    "# Once you have an NPLinker object with all data loaded, there are a collection of simple\n",
    "# methods and properties you can use to access objects and metadata. Some examples are \n",
    "# given below, see https://nplinker.readthedocs.io/en/latest/ for a complete API description.\n",
    "\n",
    "# configuration/dataset metadata\n",
    "# - a copy of the configuration as parsed from the .toml file (dict)\n",
    "print(npl.config) \n",
    "# - the path to the directory where various nplinker data files are located (e.g. the \n",
    "#   default configuration file template) (str)\n",
    "print(npl.data_dir)\n",
    "# - a dataset ID, derived from the path for local datasets or the paired platform ID\n",
    "#   for datasets loaded from that source (str)\n",
    "print(npl.dataset_id)\n",
    "# - the root directory for the current dataset (str)\n",
    "print(npl.root_dir)\n",
    "\n",
    "# objects\n",
    "# - you can directly access lists of each of the 4 object types:\n",
    "print('BGCs:', len(npl.bgcs))\n",
    "print('GCFs:', len(npl.gcfs)) # contains GCF objects\n",
    "print('Spectra:', len(npl.spectra)) # contains Spectrum objects\n",
    "print('Molecular Families:', len(npl.molfams)) # contains MolecularFamily objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring functionality - part 1\n",
    "# ==============================\n",
    "# (again see https://nplinker.readthedocs.io/en/latest/ for API documentation)\n",
    "\n",
    "# NPLinker provides a set of scoring methods that can be used individually or \n",
    "# in combination to find interesting links in the current dataset. To get a\n",
    "# get a list of the names of the available scoring methods:\n",
    "print('Available scoring methods:')\n",
    "for m in npl.scoring_methods:\n",
    "    print(' - {}'.format(m))\n",
    "    \n",
    "# The first step in running a scoring operation is to get an instance of the\n",
    "# method(s) you want to use by calling scoring_method():\n",
    "mc = npl.scoring_method('metcalf')\n",
    "\n",
    "# Now mc is an instance of the class that implements Metcalf scoring. Once\n",
    "# you have such an instance, you may change any of the parameters it exposes.\n",
    "# In the case of Metcalf scoring, the following parameters are currently exposed:\n",
    "# - cutoff (float): the scoring threshold. Links with scores less than this are excluded\n",
    "# - standardised (bool): set to True to use standardised scores (default), False for regular\n",
    "mc.cutoff = 2.5\n",
    "mc.standardised = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring functionality - part 2\n",
    "# ==============================\n",
    "\n",
    "# After creating and optionally configuring a scoring method, you need to call\n",
    "# get_links() to perform the operation on a selected set of objects. This method\n",
    "# takes 2-3 parameters, the third being optional:\n",
    "#  - a list of objects to find links from (or a list of lists of objects)\n",
    "#  - a list of scoring methods, or a single method as shorthand for a 1-element list\n",
    "#  - (optional) a boolean indicating if results from multiple methods should be \n",
    "#     ANDed together to produce the final results. If set to False, the results will\n",
    "#     contain links found by any method rather than all methods. \n",
    "# \n",
    "# This first example shows the simplest case: 1 set of objects and 1 scoring method. \n",
    "# If the and_mode parameter is not given it defaults to True, but the value doesn't \n",
    "# matter here because only one method is being used. \n",
    "results = npl.get_links(npl.gcfs, mc, and_mode=True) \n",
    "\n",
    "# get_links returns an instance of a class called LinkCollection. This provides a wrapper\n",
    "# around the results of the scoring operation and has various useful properties/methods:\n",
    "#\n",
    "# - len(results) or .source_count will tell you how many of the input_objects were found to have links\n",
    "print('Number of results: {}'.format(len(results)))\n",
    "# - .sources is a list of those objects\n",
    "objects_with_links = results.sources\n",
    "# - .links is a dict with structure {input_object: {linked_object: ObjectLink}} \n",
    "objects_and_link_info = results.links\n",
    "# - .get_all_targets() will return a flat list of *all* the linked objects (for all sources)\n",
    "all_targets = results.get_all_targets() \n",
    "# - .methods is a list of the scoring methods passed to get_links\n",
    "methods = results.methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring functionality - part 3\n",
    "# ==============================\n",
    "# \n",
    "# The link data inside the LinkCollection object is itself stored in ObjectLink objects.\n",
    "# Each instance of an ObjectLink represents a link between a given pair of objects as\n",
    "# determined by 1 or more scoring methods. \n",
    "#\n",
    "# ObjectLinks have the following basic attributes:\n",
    "# - .source: the input object provided to the method\n",
    "# - .target: the linked object\n",
    "# - .methods: a list of the methods that found this link\n",
    "# - .shared_strains: a list of Strain objects (possibly empty) shared between .source and .target\n",
    "# - .data(<method_object>): return the output of <method_object> for this link (e.g. any score values)\n",
    "# \n",
    "# You can also retrieve any method-specific info for a link by subscripting these objects with \n",
    "# the appropriate method object, e.g. metcalf_link_data = object_link[mc] \n",
    "\n",
    "# This shows how to iterate over the link information from result.links. In the body of the loop\n",
    "# <obj> will be one of  the original objects supplied to get_links and <result> will be a dict \n",
    "# with structure {linked_object: ObjectLink} (indicating <obj> is linked to <linked_object> according to\n",
    "# the information stored in the ObjectLink)\n",
    "curr_obj = None\n",
    "staur_objs = []\n",
    "staur_links = []\n",
    "for obj, result in results.links.items():\n",
    "    # display the object, the number of links it has, and the number of methods that were used to get them\n",
    "#     print('Results for object: {}, {} total links, {} methods used'.format(obj, len(result), results.method_count))\n",
    "    \n",
    "    # sorting is method-dependent since they might have very different \"scores\", so you should\n",
    "    # use the original object to do this. For Metcalf scoring, this will return the ObjectLinks sorted\n",
    "    # by their Metcalf scores. \n",
    "    sorted_links = results.get_sorted_links(mc, obj)\n",
    "    # or if you wanted them in the reverse order:\n",
    "    # sorted_links = results.get_sorted_links(mc, obj, reverse=True)\n",
    "    \n",
    "    # Now display some link information for each link associated with <obj>.\n",
    "    # link_data[<method_object>] will return the per-link data generated by that \n",
    "    # method. Here the metcalf method simply returns the link score as a floating point value,\n",
    "    # but other methods may return more complex objects. \n",
    "    # \n",
    "    # Each scoring method also has a format_data method which should provide a relatively short \n",
    "    # human-readable summary of the data, as a quick way to print and examine results.\n",
    "    for link_data in sorted_links:\n",
    "        if obj.gcf_id == 3327:  # try catching staurosporine\n",
    "            print('Results for object: {}, {} total links, {} methods used'.format(obj, len(result), results.method_count))\n",
    "            print('  --> [{}] {} | {} | shared strains = {}'.format(','.join(method.name for method in link_data.methods), \n",
    "                                                                    link_data.target, \n",
    "                                                                    mc.format_data(link_data[mc]), \n",
    "                                                                    len(link_data.shared_strains)))\n",
    "            staur_objs.append(obj)\n",
    "            staur_links.append(link_data)\n",
    "        \n",
    "#         if len(link_data.shared_strains) > 4 and \"Others\" not in obj.classes:\n",
    "#             if curr_obj != obj.id:\n",
    "#                 print('Results for object: {}, {} total links, {} methods used'.format(obj, len(result), results.method_count))\n",
    "#             curr_obj = obj.id\n",
    "#             print('  --> [{}] {} | {} | shared strains = {}'.format(','.join(method.name for method in link_data.methods), \n",
    "#                                                                     link_data.target, \n",
    "#                                                                     mc.format_data(link_data[mc]), \n",
    "#                                                                     len(link_data.shared_strains)))\n",
    "        \n",
    "    # alternatively, if you don't care about ordering, you can just iterate directly over the \n",
    "    # linked objects like this:\n",
    "    # for link_target, link_data in result.items():\n",
    "    \n",
    "    #    print(link_target, link_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "staur_objs[0], staur_links[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npl.strains._strains, len(npl.strains._strains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring functionality - part 4\n",
    "# ==============================\n",
    "#\n",
    "# The LinkCollection object supports performing various types of filtering on the original set of\n",
    "# results contained within it:\n",
    "# - .filter_no_shared_strains(): remove any links where the linked objects do not share strains\n",
    "# - .filter_sources(callable), .filter_targets(callable), .filter_links(callable): each of these\n",
    "#     simply execute callable(object) and filter out objects for which the return value is False/0. \n",
    "#     The <objects> in each case are respectively: the original input objects (sources), \n",
    "#     their linked objects (targets), and the ObjectLink objects (links).\n",
    "#\n",
    "# NOTE:\n",
    "# - these methods all modify the original LinkCollection in-place\n",
    "# - they will automatically remove any original results for which no links exist after filtering. For\n",
    "#    example, if there is a source object which starts off with 2 links, but has 0 after a filter is\n",
    "#    run, this object will not appear in the LinkCollection afterwards.\n",
    "#\n",
    "# Examples:\n",
    "# - exclude any sources for which an arbitrary function is false (sources are GCFs in this example)\n",
    "results.filter_sources(lambda gcf: gcf.id % 2 == 0)\n",
    "# - exclude any linked objects for which an arbitrary function is false (targets are Spectrum objects here)\n",
    "results.filter_targets(lambda spec: spec.id % 1 == 0)\n",
    "# - exclude any links for which an arbitrary function is false (<link> is an ObjectLink)\n",
    "results.filter_links(lambda link: link[mc] > 3.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring functionality - part 5\n",
    "# ==============================\n",
    "# \n",
    "# The get_links method can be passed more complex parameters types than the above example which \n",
    "# used a flat list of input objects and a single scoring method instance. \n",
    "\n",
    "ts = npl.scoring_method('testscore') # copy of Metcalf method, only for debug use\n",
    "\n",
    "# You can use the same set of objects with two different methods, and AND the results\n",
    "# together so that objects will only be returned which have links according to \n",
    "# BOTH of the supplied methods (if you provide 2 or more scoring methods but only a single \n",
    "# set of objects, that set will be used as input to every method).\n",
    "results = npl.get_links(npl.gcfs[:10], [mc, ts], and_mode=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
