{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from nplinker import NPLinker\n",
    "from logconfig import LogConfig\n",
    "from metabolomics import Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuring NPLinker in a notebook env is now done either by passing in the name of a config file,\n",
    "# or by passing in a dict which corresponds to the structure of the config file. Usually it will be\n",
    "# easier to edit the file and simply pass the filename like this:\n",
    "npl = NPLinker('latest_api_demo.toml')\n",
    "\n",
    "# the above step will attempt to discover the files to be loaded from the dataset and complain\n",
    "# if they're not as expected. Next, actually load the data files\n",
    "if not npl.load_data():\n",
    "    raise Exception('Failed to load data')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The scoring methods are defined and configured in the default configuration file at \n",
    "# ~/.config/nplinker/nplinker.toml, but will be overridden by the config file you loaded above,\n",
    "# and the scoring methods can be easily changed once the NPLinker object has been created, e.g.:\n",
    "\n",
    "# ensure only metcalf scoring is enabled, and set a 99% significance percentile threshold\n",
    "print('Currently enabled scoring methods: {}'.format(npl.scoring.enabled()))\n",
    "npl.scoring.likescore.enabled = False\n",
    "# npl.scoring.likescore.cutoff = <scoring cutoff threshold>\n",
    "npl.scoring.hg.enabled = False\n",
    "# npl.scoring.hg.prob = <probability threshold>\n",
    "npl.scoring.metcalf.enabled = True\n",
    "npl.scoring.metcalf.sig_percentile = 99\n",
    "print('Currently enabled scoring methods: {}'.format(npl.scoring.enabled()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this step generates scores for all objects and enabled scoring methods, so it can be\n",
    "# quite lengthy. The random_count parameter determines the number of randomised instances\n",
    "# of Spectrum <=> Strain mappings that will be generated during the process.\n",
    "if not npl.process_dataset(random_count=10):\n",
    "    raise Exception('Failed to process dataset')\n",
    "print('Completed generating scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get results once the scores are generated, first select an object you're interested \n",
    "# in, then call get_links with a specific scoring method. You can also pass a list of \n",
    "# objects as the first parameter. The method returns a list which contains only those\n",
    "# objects that satisfy the scoring criteria (so here only those with a significance \n",
    "# percentile score of >= 99 as set above)\n",
    "test_gcf = npl.gcfs[8]\n",
    "results = npl.get_links(test_gcf, npl.scoring.metcalf)\n",
    "if test_gcf not in results:\n",
    "    print('No results found!')\n",
    "else:\n",
    "    print('Found results for {}!'.format(test_gcf))\n",
    "    # to get the objects that scored highly against this GCF, use links_for_obj. By\n",
    "    # default it will return all objects, the type_ parameter can be used to filter\n",
    "    # by class, so here it will only return spectra\n",
    "    test_gcf_links = npl.links_for_obj(test_gcf, npl.scoring.metcalf, type_=Spectrum)\n",
    "    \n",
    "    # print the objects and their scores, plus common strains\n",
    "    for obj, score in test_gcf_links:\n",
    "        print('{} : score {}'.format(obj, score))\n",
    "        # returns a dict indexed by (Spectrum, GCF) tuples, with \n",
    "        # the values being lists of strain names shared between the two\n",
    "        common_strains = npl.get_common_strains(test_gcf, obj)\n",
    "        if len(common_strains) > 0:\n",
    "            strain_names = list(common_strains.values())[0]\n",
    "            print('   {} shared strains: {}'.format(len(strain_names), strain_names))\n",
    "        else:\n",
    "            print('   (no shared strains)')\n",
    "            \n",
    "    print('{} total links found'.format(len(test_gcf_links)))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
